library(roxygen2)
setwd("~/GitHub/PRAWNS")
document()
library(devtools)
document()
document()
document()
document()
document()
document()
setwd("~/GitHub")
setwd("~/GitHub")
install("PRAWNS")
setwd("~/GitHub/PRAWNS use")
setwd("~/GitHub")
library(devtools)
setwd("~/GitHub/Data-analysis-with-PRAWNS-demo")
create_prawns(raster_path= "Data/NOx_rasters_2019",
shapefile_path = "Data/LSOA shapefile",
data_path= list.files("Data/LSOA_statistics"),
key_variable = "LSOA19CD",
key_variable_aliases =c("LSOA.code..2011.","?..LSOA11CD"),
output_path="Outputs/create_prawns_1_0_0_test")
raster_path= "Data/NOx_rasters_2019"
shapefile_path = "Data/LSOA shapefile"
data_path= list.files("Data/LSOA_statistics")
key_variable = "LSOA19CD"
key_variable_aliases =c("LSOA.code..2011.","?..LSOA11CD")
output_path="Outputs/create_prawns_1_0_0_test"
#Create a list of all the raster files present in the folder specified by raster_path
filelist <- list.files(raster_path,
pattern = ".asc",
full.names = TRUE)
#Store the rasters as a stack
source_stack <- rast(filelist[1])
source("~/GitHub/PRAWNS/R/create_prawns.R", encoding = 'UTF-8')
library(raster)
library(sf)
library(tidyverse)
library(terra)
library(exactextractr)
library(rlang)
library(broom)
library(ggpubr)
library(colorspace)
library(viridis)
library(googledrive)
library(stars)
library(devtools)
library(roxygen2)
#Store the rasters as a stack
source_stack <- rast(filelist[1])
for(index in 2:length(filelist)){
source_stack <- c(source_stack,rast(filelist[index]))
}
source_stack
#Read the shapefile
LSOA_shapefile <- vect(shapefile_path)
#Calculate the average for each polygon in the shapefile
index <-  c(1:length(LSOA_shapefile))
transient <- sf::st_as_sf(LSOA_shapefile[index])
length(LSOA_shapefile)
pollution_mean <- exact_extract(source_stack,transient,'mean')
#Output the results as a tibble containing the indexed position, the pollution mean and the LSOA code, a property from the shapefile that enables binding on LSOA statistics
output <- tibble(FID=index,poll_mean=pollution_mean,LSOA11CD=LSOA_shapefile$LSOA11CD) %>% unnest(pollution_mean)
LSOA_shapefile[1]
LSOA_shapefile[2]
LSOA_shapefile[1][2]
View(LSOA_shapefile)
length(LSOA_shapefile)
shapefile_path = "Data/2011_LSOA_shapefile_20m_generalised"
#Read in necessary files for function operation
#Reads LSOAs as a shapefile
LSOA_shapefile <- vect("Data/2011_LSOA_shapefile_20m_generalised")
#Calculate the average for each polygon in the shapefile
index <-  c(1:length(LSOA_shapefile))
length(index)
transient <- sf::st_as_sf(LSOA_shapefile[index])
pollution_mean <- exact_extract(source_stack,transient,'mean')
#Output the results as a tibble containing the indexed position, the pollution mean and the LSOA code, a property from the shapefile that enables binding on LSOA statistics
output <- tibble(FID=index,poll_mean=pollution_mean,LSOA11CD=LSOA_shapefile$LSOA11CD) %>% unnest(pollution_mean)
LSOA_shapefile$LSOA11CD
#Output the results as a tibble containing the indexed position, the pollution mean and the LSOA code, a property from the shapefile that enables binding on LSOA statistics
output <- tibble(FID=index,
poll_mean=pollution_mean,
LSOA11CD=LSOA_shapefile$LSOA11CD) %>% unnest(pollution_mean)
#Output the results as a tibble containing the indexed position, the pollution mean and the LSOA code, a property from the shapefile that enables binding on LSOA statistics
output <- tibble(FID=index,
#poll_mean=pollution_mean,
LSOA11CD=LSOA_shapefile$LSOA11CD) %>% unnest(pollution_mean)
#Output the results as a tibble containing the indexed position, the pollution mean and the LSOA code, a property from the shapefile that enables binding on LSOA statistics
output <- tibble(FID=index,
poll_mean=pollution_mean,
#LSOA11CD=LSOA_shapefile$LSOA11CD) %>% unnest(pollution_mean)
#
# Read the additional data as a list of tibbles----------------------------------------------------------------
additional_data <- list()
for (count in c(1:length(data_path))){
#Read the file as a tibble and hold it in a transition state whilst it's checked for errors
ts <- read.csv(data_path[count],row.names=1) %>% tibble()
#Check for a known formatting issue in the column names and correct it
if (colnames(ts)[1]== "Ã¯..LSOA11CD"||colnames(ts)[1]== "LSOA.code..2011."){
colnames(ts)[1] <- "LSOA11CD"
}
#Store the transition state in the list of data
additional_data[count] <- ts
}
#Create a tibble to collect all the additional data in
additional_data_tibble <- additional_data[1]
#If there's more than one table of additional data, combine them all
if(length((additional_data)>1)){
for (count in c(2:length(additional_data))){
inner_join(additional_data_tibble,additional_data[count],by="LSOA11CD")
}}
# Combine the pollution means with the additional data --------------------
prawns <- inner_join(output,refined_chunk,by="LSOA11CD")
#Link the averages for each polygon with the additional data
#Save the results if a filepath was specified
#Return the resulting object
# Output the results ------------------------------------------------------
if (output_path!=FALSE){
write.csv(prawns,
file=output_path)
}
prawns
}
#Output the results as a tibble containing the indexed position, the pollution mean and the LSOA code, a property from the shapefile that enables binding on LSOA statistics
output <- tibble(FID=index,
poll_mean=pollution_mean,
#LSOA11CD=LSOA_shapefile$LSOA11CD
) %>% unnest(pollution_mean)
#Output the results as a tibble containing the indexed position, the pollution mean and the LSOA code, a property from the shapefile that enables binding on LSOA statistics
output <- tibble(FID=index,
poll_mean=pollution_mean,
LSOA11CD=LSOA_shapefile$LSOA11CD
)
#Output the results as a tibble containing the indexed position, the pollution mean and the LSOA code, a property from the shapefile that enables binding on LSOA statistics
output <- tibble(FID=index,
poll_mean=pollution_mean,
LSOA11CD=LSOA_shapefile$LSOA11CD
) %>% unnest(poll_mean)
additional_data <- list()
use_readme_md()
setwd("~/GitHub/PRAWNS")
use_readme_md()
use_readme_md()
